train:
  epochs: 100
  training_steps_per_epoch: 400
  batch_size: 32
  sequence_length: 64
  latent_dim: 32
  codes_per_latent: 32